{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test with a holdout dataset.ipynb","provenance":[],"collapsed_sections":["0ybBZYkfh2xQ"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Test with a holdout dataset\n","This notebook contains only a subset of the code present in the \"*solution notebook*\" to simplify the testing on the holdout dataset.\n","\n","You just need to execute all the cells that follows these steps:\n","1.   Upload all the needed file on the notebook or connect it to a Google Drive account in which these files are accesible. \n","2.   Extract features from samples and save them loacally on the VM.\n","3.   Load the features extracted and give them as input to the ensemble model or chose the model you want to test and then feed it with the extracted features. \n","4. Save the result on a csv file. "],"metadata":{"id":"69PNFvibdv3r"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9wlujzxfFAW"},"outputs":[],"source":["# Import all the needed libraries\n","import os\n","import tqdm\n","import librosa\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","from google.colab import files\n","from tensorflow.keras import layers\n","from tensorflow.keras.utils import normalize\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","source":["# Gloval variable definition \n","TARGET_COLUMN = \"emotion\"\n","NUM_CLASSES = 7\n","CLASS_NAMES = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sadness', 'surprise']\n","TEST_SET_PREDICTIONS_FILE='/path/to/the file with prediction'   #@param {type: \"string\"}\n","\n","# Dictionaries that maps class code to class name and vice versa\n","id2label = {str(i): label for i, label in enumerate(CLASS_NAMES)}\n","label2id = {v: k for k, v in id2label.items()}"],"metadata":{"id":"ojs-kvzNfUu4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get needed file\n","I have prepared two ways to get the file needed:\n","\n","\n","1.  **Upload data** from your file system.\n","2.  **Connect a Google Drive** in which you have this directory to the Notebook to get data.\n","\n","Execute one of the following section, depending on your preference.\n","The value of some global variable depends on this choice.\n","\n"],"metadata":{"id":"DjWC0N22Je68"}},{"cell_type":"markdown","source":["## Upload data from your FS\n","\n","Upload the dataframe with the holdout test along the directory with the audio files and the ensemble models directory, which contains all the best trained model I have submitted."],"metadata":{"id":"0ybBZYkfh2xQ"}},{"cell_type":"code","source":["# upload the csv with the test set\n","uploaded = files.upload()"],"metadata":{"id":"PBembUbKgFQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload the ensemble model directory\n","uploaded = files.upload()"],"metadata":{"id":"BhO97aKdi98j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload the stacking model directory\n","uploaded = files.upload()"],"metadata":{"id":"zKetgAXQFc2Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload the all_models model directory\n","uploaded = files.upload()"],"metadata":{"id":"LXvUzm9AKalX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload the directory with the audio files\n","uploaded = files.upload()"],"metadata":{"id":"Tauq-6Snjg2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Global variable definition\n","TEST_FILE = \"2022challengeA_test.csv\"\n","TEST_DIR = \"test/\"\n","\n","ENSEMBLE_MODELS_PATH = \"ensemble_models/\"\n","STACKING_MODELS_PATH = \"stacking_models/\"\n","ALL_MODELS_PATH = \"all_models/\"\n","\n","# List with all the names of models that join the ensemble\n","MODELS_TO_ENSEMBLE = [model_name for model_name in os.listdir(ENSEMBLE_MODELS_PATH) if 'h5' in model_name]"],"metadata":{"id":"15LpxFGnJV4g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Connect Google Drive"],"metadata":{"id":"uU55oIOyKh2m"}},{"cell_type":"code","source":["# Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Global variable definition\n","TEST_FILE = \"path/to/your/csv with the test set\"  #@param {type: \"string\"}\n","TEST_DIR = \"path/to/your/directory with all the audios present in the test set\"   #@param {type: \"string\"}                 \n","\n","ALL_MODELS_PATH = \"path/to/your/directory with all the models\"        #@param {type: \"string\"}\n","STACKING_MODELS_PATH = \"path/to/your/directory with all the stacking models\"  #@param {type: \"string\"}\n","ENSEMBLE_MODELS_PATH = \"path/to/your/directory with all the ensemble models\"  #@param {type: \"string\"}\n","\n","# List with all the names of models that join the ensemble\n","MODELS_TO_ENSEMBLE = [model_name for model_name in os.listdir(ENSEMBLE_MODELS_PATH) if 'h5' in model_name]"],"metadata":{"id":"Drd1PqaoKwOr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Extract Feature"],"metadata":{"id":"KUaynY2sfj1W"}},{"cell_type":"code","source":["def extract_feature_1D(file_name, mfcc=True, chroma=True, mel=True):\n","  '''Extract 1D features from the audio file given as input..\n","    Parameters\n","    ----------\n","    file_name: audio file to be processed.\n","    \n","    mfcc: boolean to specify if the Mel-frequency cepstral coefficients features has to be extracted.\n","\n","    chroma: boolean to specify if the chromagram features has to be extracted.\n","\n","    mel: boolean to specify if the log mel spectogram features has to be extracted.\n","\n","    Return\n","    ----------\n","    features: numpy.ndarray with the extracted features.\n","  '''\n","  X, sample_rate = librosa.load(file_name)\n","  features=np.array([])  \n","  if mfcc:\n","    mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n","    features=np.hstack((features, mfccs))\n","  if chroma:\n","    stft=np.abs(librosa.stft(X))\n","    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n","    features=np.hstack((features, chroma))\n","  if mel:\n","    mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n","    features=np.hstack((features, mel))\n","\n","  return features\n","\n","\n","def extract_feature_2D(path, n_fft, hop_length, n_mels):\n","    \"\"\" Extract log mel spectrogram to audio file, which are all padded to 8 seconds to get same length features.\n","    Return:\n","        log_mel_spectrogram: nd.array with the log mel spectogram of the audio specified with the path\n","    \"\"\"\n","    y, sr = librosa.load(path, sr=16000, duration=8)\n","\n","    file_length = np.size(y)\n","    if file_length != 128000:\n","        y = np.concatenate((y, np.zeros(128000-file_length)), axis=0)\n","\n","    mel_spectrogram = librosa.feature.melspectrogram(y, sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n","    log_mel_spectrogram = librosa.amplitude_to_db(mel_spectrogram)\n","    log_mel_spectrogram = log_mel_spectrogram.reshape((-1,))\n","\n","    return log_mel_spectrogram\n","\n","\n","def extract_features(annot, feature_type):\n","  '''Extract and save and save in a file the features from all the audios contained in the dataset, which has to be passed as a pandas dataframe.\n","    Parameters\n","    ----------\n","    annot: pandas dataframe which contains the dataset with labels on column \"emotion\" and file name in the column \"file_id\".\n","\n","    \n","    feature_type: type of feature you need, Possibilities are \"1D\" for 1D-feature and \"2D\" for 2D-features.\n","\n","    Return\n","    ----------\n","    dataset: tf.data.Dataset cached and batched\n","    features2D: numpy.ndarray with the 2D features needed.\n","    labels: numpy.ndarray with the ground thruth.\n","  '''\n","  files = annot['file_id'].to_list()\n","  features = []\n","\n","  for i in tqdm.tqdm(range(len(files))):\n","    try:\n","      file = files[i]\n","      fname = os.path.join(TEST_DIR, file)\n","      \n","      if feature_type == \"1D\":\n","          sample = extract_feature_1D(fname, mfcc=True, chroma=False, mel=False)\n","      elif feature_type == \"2D\":\n","        sample = extract_feature_2D(fname, n_fft=2048, hop_length=512, n_mels=128)\n","\n","      features.append(sample)\n","    except Exception as e:\n","      print(\"\\n\", file)\n","      print(e)\n","    \n","  features = np.array(features)\n","  \n","  if feature_type == \"2D\":\n","    features = features.reshape(-1, 128, 251, 1)\n","\n","  feature_file = feature_type + \".npy\" \n","\n","  with open(feature_file, 'wb') as f:\n","    np.save(f, features)\n","\n","\n","def get_features(feature_type):\n","  '''Read the features stored in the npy, scale and return them as a numpy.ndarray'''\n","  with open(feature_type + \".npy\", 'rb') as f:\n","    features = np.load(f)\n","  \n","  features = scale_features(features)\n","  return features\n","\n","\n","def scale_features(features):\n","  '''Scale the features given as input using the standard scaler, thus obtaining zero-mean and unitary std'''\n","  scaler = StandardScaler()\n","  \n","  features_shape = features.shape\n","  \n","  features = np.reshape(features, (features_shape[0],-1)) \n","  scaled_features = scaler.fit_transform(features)\n","  scaled_features = np.reshape(scaled_features, features_shape)\n","\n","  return scaled_features\n","\n","\n","def weighted_average(models_scores):\n","  '''Returns the weighted score predictions.'''\n","  # Use the weights found with the Genetic Algorithm \n","  weights=[0.2011812,  0.27912898, 0.12519793, 0.07452854, 0.1335278,  0.18643554]\n","  weighted_scores = []\n","  for i in range(len(models_scores[0])):\n","    weighted_score = [weight*scores[i] for weight, scores in zip(weights, models_scores)]\n","    weighted_average = np.sum(weighted_score, axis = 0)\n","    weighted_scores.append(weighted_average)\n","  return weighted_scores\n","\n","\n","class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n","        super(TransformerBlock, self).__init__()\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.ff_dim = ff_dim\n","        self.rate = rate\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = keras.Sequential(\n","            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update({\n","              'embed_dim': self.embed_dim,\n","              'num_heads': self.num_heads,\n","              'ff_dim': self.ff_dim,\n","              'rate': self.rate\n","        })\n","        return config"],"metadata":{"id":"h9eEI5hWfiYR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_annot = pd.read_csv(TEST_FILE, index_col=0)\n","extract_features(test_annot, \"1D\")   # extract features and save them in a file called 1D.npy\n","extract_features(test_annot, \"2D\")   # extract features and save them in a file called 2D.npy"],"metadata":{"id":"tzxRqwPRpndj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ensemble"],"metadata":{"id":"PnXKaGVwm4LR"}},{"cell_type":"code","source":["# Define an array with all the ensemble models loaded from the directory \"ensemble_models\"\n","models = []\n","for i, model_name in enumerate(MODELS_TO_ENSEMBLE):\n","  model = tf.keras.models.load_model(os.path.join(ENSEMBLE_MODELS_PATH, model_name), custom_objects={\"TransformerBlock\": TransformerBlock})\n","  model._name = f'model_{i}'\n","  models.append(model)"],"metadata":{"id":"KFBz244vfbrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the features saved in the files 1D.npy and 2D.npy\n","MONO_DIM_TEST_DS = get_features(\"1D\")   \n","TWO_DIM_TEST_DS = get_features(\"2D\")\n","\n","FUSED_TEST_DS = {\"features_1D\": MONO_DIM_TEST_DS, \"features_2D\": TWO_DIM_TEST_DS}"],"metadata":{"id":"nJoBf1g4nRzD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a model with the predictions (probability distribution over all the labels) of all the models ensemble \n","TEST_SCORES = []\n","for i, model_name in enumerate(MODELS_TO_ENSEMBLE):\n","  if '1D' in model_name:\n","    TEST_SCORES.append(models[i].predict(MONO_DIM_TEST_DS, verbose=1))\n","  elif 'fused' in model_name :\n","    TEST_SCORES.append(models[i].predict(FUSED_TEST_DS, verbose=1))\n","  else:\n","    TEST_SCORES.append(models[i].predict(TWO_DIM_TEST_DS, verbose=1))"],"metadata":{"id":"GnsKMTcQm8Ga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make an average of all the predictions using the weights found with the genetic algorithm\n","ensemble_scores = weighted_average(TEST_SCORES)\n","\n","# Select the label to assign to each sample as the one with the highest probability \n","ensemble_predictions = np.argmax(ensemble_scores, axis=1)"],"metadata":{"id":"HBg12khAoAkP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the code of the label predicted with the name of the class\n","test_annot = pd.read_csv(TEST_FILE, index_col=0)\n","label_prediction = [id2label[str(prediction)] for prediction in ensemble_predictions]\n","test_annot['predicted_emotion'] = label_prediction\n","\n","# Store the result into a pandas Dataframe\n","test_annot.to_csv(TEST_SET_PREDICTIONS_FILE, index=False)\n","test_annot = pd.read_csv(TEST_SET_PREDICTIONS_FILE)\n","test_annot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"LUHwTjGkZWFR","executionInfo":{"status":"ok","timestamp":1654960824723,"user_tz":-120,"elapsed":40,"user":{"displayName":"ALESSIO SERRA","userId":"10572653186885782029"}},"outputId":"762f0a6d-1453-4b18-c7f2-dc1fa9715bbd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                       file_id origin predicted_emotion\n","0     030472df-9d70-4d76-a1a5-acb4c33537d3.wav  crema           sadness\n","1     ac4720de-e0d9-4667-86a7-4236d410ed25.wav  crema             happy\n","2     264928af-cb15-4125-abf7-9408369d83b2.wav  crema              fear\n","3     2233ce2b-35ae-483c-9397-1058f681b6ef.wav  crema           disgust\n","4     472aa1eb-b4dc-452c-84b7-934ed61285da.wav  crema              fear\n","...                                        ...    ...               ...\n","1380  1656443f-b726-49a7-b572-534bfdecc6c8.wav   tess             angry\n","1381  d4243d13-0ba7-41e1-90ad-7881e946fce6.wav   tess           disgust\n","1382  d92d1675-aba4-4c57-a48e-6ee8037a9d36.wav   tess           neutral\n","1383  34c3505d-4325-4d3d-8207-723950e7268d.wav   tess          surprise\n","1384  8ef99363-2516-40a1-a94c-6630d49d6ba1.wav   tess           neutral\n","\n","[1385 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-43b0e5e0-f3dd-4d7d-afc5-0546aae14152\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_id</th>\n","      <th>origin</th>\n","      <th>predicted_emotion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>030472df-9d70-4d76-a1a5-acb4c33537d3.wav</td>\n","      <td>crema</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ac4720de-e0d9-4667-86a7-4236d410ed25.wav</td>\n","      <td>crema</td>\n","      <td>happy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>264928af-cb15-4125-abf7-9408369d83b2.wav</td>\n","      <td>crema</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2233ce2b-35ae-483c-9397-1058f681b6ef.wav</td>\n","      <td>crema</td>\n","      <td>disgust</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>472aa1eb-b4dc-452c-84b7-934ed61285da.wav</td>\n","      <td>crema</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1380</th>\n","      <td>1656443f-b726-49a7-b572-534bfdecc6c8.wav</td>\n","      <td>tess</td>\n","      <td>angry</td>\n","    </tr>\n","    <tr>\n","      <th>1381</th>\n","      <td>d4243d13-0ba7-41e1-90ad-7881e946fce6.wav</td>\n","      <td>tess</td>\n","      <td>disgust</td>\n","    </tr>\n","    <tr>\n","      <th>1382</th>\n","      <td>d92d1675-aba4-4c57-a48e-6ee8037a9d36.wav</td>\n","      <td>tess</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1383</th>\n","      <td>34c3505d-4325-4d3d-8207-723950e7268d.wav</td>\n","      <td>tess</td>\n","      <td>surprise</td>\n","    </tr>\n","    <tr>\n","      <th>1384</th>\n","      <td>8ef99363-2516-40a1-a94c-6630d49d6ba1.wav</td>\n","      <td>tess</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1385 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43b0e5e0-f3dd-4d7d-afc5-0546aae14152')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-43b0e5e0-f3dd-4d7d-afc5-0546aae14152 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-43b0e5e0-f3dd-4d7d-afc5-0546aae14152');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# Single model"],"metadata":{"id":"ZIkA_obgoG5V"}},{"cell_type":"code","source":["# Get the features saved in the files 1D.npy and 2D.npy\n","MONO_DIM_TEST_DS = get_features(\"1D\")   \n","TWO_DIM_TEST_DS = get_features(\"2D\")\n","\n","FUSED_TEST_DS = {\"features_1D\": MONO_DIM_TEST_DS, \"features_2D\": TWO_DIM_TEST_DS}"],"metadata":{"id":"KDOxvuEc90TE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a dictionary that maps each model with its input \n","map_model_to_ds = {'cnn_lstm_1D.h5':MONO_DIM_TEST_DS, 'stacking_ensemble.h5': TWO_DIM_TEST_DS, 'cnn_transformer.h5':TWO_DIM_TEST_DS, 'cnn_lstm_2D.h5':TWO_DIM_TEST_DS, 'cnn_lstm_fused.h5':FUSED_TEST_DS, '2D_lstm_cnn.h5':TWO_DIM_TEST_DS, '1D_lstm_cnn.h5':MONO_DIM_TEST_DS}"],"metadata":{"id":"3rxnV-jsoJHG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Chose the model you want to load (from the ensemble directory), but if you can change it to the all models directory and test anything you want\n","MODEL_NAME = \"cnn_transformer.h5\"\n","\n","MODEL_TO_LOAD = ENSEMBLE_MODELS_PATH + MODEL_NAME   # you can also change the directory, e.g. STACKING_MODELS_PATH + MODEL_NAME\n","\n","# Load the model \n","model_loaded = tf.keras.models.load_model((MODEL_TO_LOAD), custom_objects={\"TransformerBlock\": TransformerBlock})\n","\n","# Get the probability distribution over all the labels for each sample\n","model_scores = model_loaded.predict(map_model_to_ds[MODEL_NAME])\n","\n","# Get the code of the class with the highest probability \n","model_predictions = np.argmax(model_scores, axis=1)"],"metadata":{"id":"FRJmZrAVomsr"},"execution_count":null,"outputs":[]}]}